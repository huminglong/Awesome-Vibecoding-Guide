# AI调试中的人类上下文问题

**关于"AI无法调试这个"情况的不舒服真相。**

---

## 目录
- [不舒服的真相](#不舒服的真相)
- [为什么发生这种情况](#为什么发生这种情况)
- [人类优先框架](#人类优先框架)
- [真实世界示例](#真实世界示例)
- [上下文收集检查清单](#上下文收集检查清单)
- [何时涉及AI](#何时涉及ai)
- [重新开始的神话](#重新开始的神话)
- [常见场景](#常见场景)
- [最佳实践](#最佳实践)

---

## 不舒服的真相

**如果您被迫在项目上"重新开始"，您要么是：**

1. **在企业级别开发超级复杂的东西**（5%的情况）
2. **试图强行前进而不是正确指导AI**（95%的情况）

主要问题不是您的AI工具、模型或上下文窗口限制。

**主要问题是人类缺乏上下文知识，而不是AI窗口。**

### 真正的问题

人们不能（或不）：
- 打开浏览器DevTools并复制粘贴控制台中打印的错误
- 检查网络请求以查看实际发送/接收的内容
- 查看服务器日志以查看后端发生了什么
- 提供确切的复现步骤
- 分享实际的错误消息

相反，他们推动AI调试**AI毫无头绪的事情**，因为**人类也缺少上下文**。

然后他们责怪：
- ❌ "AI不擅长调试"
- ❌ "上下文窗口太小"
- ❌ "模型产生幻觉"
- ❌ "需要开始一个新项目"

**现实检验**：您要求AI在蒙眼的情况下调试，而您自己也蒙着眼。

---

## 为什么发生这种情况

### 1. 开发人员跳过基本调查

**常见模式：**
```
用户："提交按钮不起作用。修复它。"

AI："我需要更多信息。您看到什么错误？"

用户："它就是不起作用。你能检查代码吗？"

AI：*做出有根据的猜测，更改某些东西*

用户："还是不起作用。这个AI没用。"
```

**缺少什么**：用户从未打开DevTools。从未检查控制台。从未查看网络请求。从未尝试理解实际上什么失败了。

### 2. 害怕看起来"愚蠢"

开发人员认为：
- "我应该在不检查日志的情况下知道什么错了"
- "真正的程序员不需要DevTools来修复简单的错误"
- "AI应该从代码中弄清楚"

**真相**：专业开发人员首先检查日志。总是。这不是"愚蠢"——这是**专业**。

### 3. 误解AI的角色

**开发人员认为AI做什么：**
- 魔法般地理解运行时状态
- 有权访问浏览器控制台
- 可以看到网络请求
- 知道发生了什么错误

**AI实际看到什么：**
- 您分享的代码
- 您编写的描述
- 没有关于运行时行为的信息
- 除非您粘贴错误，否则无法访问错误

**AI不是通灵者。AI是一个只能看到您向他们展示的内容的结对程序员。**

### 4. 对"重新开始"的困惑

**开发20小时后的用户：**
> "这坏了。我应该开始一个新项目吗？"