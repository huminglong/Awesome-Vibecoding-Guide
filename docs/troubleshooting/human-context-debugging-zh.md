# AI调试中的人类上下文问题

**关于"AI无法调试这个"情况的不舒服真相。**

---

## 目录
- [不舒服的真相](#不舒服的真相)
- [为什么发生这种情况](#为什么发生这种情况)
- [人类优先框架](#人类优先框架)
- [真实世界示例](#真实世界示例)
- [上下文收集检查清单](#上下文收集检查清单)
- [何时涉及AI](#何时涉及ai)
- [重新开始的神话](#重新开始的神话)
- [常见场景](#常见场景)
- [最佳实践](#最佳实践)

---

## 不舒服的真相

**如果您被迫在项目上"重新开始"，您要么是：**

1. **在企业级别开发超级复杂的东西**（5%的情况）
2. **试图强行前进而不是正确指导AI**（95%的情况）

主要问题不是您的AI工具、模型或上下文窗口限制。

**主要问题是人类缺乏上下文知识，而不是AI窗口。**

### 真正的问题

人们不能（或不）：
- 打开浏览器DevTools并复制粘贴控制台中打印的错误
- 检查网络请求以查看实际发送/接收的内容
- 查看服务器日志以查看后端发生了什么
- 提供确切的复现步骤
- 分享实际的错误消息

相反，他们推动AI调试**AI毫无头绪的事情**，因为**人类也缺少上下文**。

然后他们责怪：
- ❌ "AI不擅长调试"
- ❌ "上下文窗口太小"
- ❌ "模型产生幻觉"
- ❌ "需要开始一个新项目"

**现实检验**：您要求AI在蒙眼的情况下调试，而您自己也蒙着眼。

---

## 为什么发生这种情况

### 1. 开发人员跳过基本调查

**常见模式：**
```
用户："提交按钮不起作用。修复它。"

AI："我需要更多信息。您看到什么错误？"

用户："它就是不起作用。你能检查代码吗？"

AI：*做出有根据的猜测，更改某些东西*

用户："还是不起作用。这个AI没用。"
```

**缺少什么**：用户从未打开DevTools。从未检查控制台。从未查看网络请求。从未尝试理解实际上什么失败了。

### 2. 害怕看起来"愚蠢"

开发人员认为：
- "我应该在不检查日志的情况下知道什么错了"
- "真正的程序员不需要DevTools来修复简单的错误"
- "AI应该从代码中弄清楚"

**真相**：专业开发人员首先检查日志。总是。这不是"愚蠢"——这是**专业**。

### 3. 误解AI的角色

**开发人员认为AI做什么：**
- 魔法般地理解运行时状态
- 有权访问浏览器控制台
- 可以看到网络请求
- 知道发生了什么错误

**AI实际看到什么：**
- 您分享的代码
- 您编写的描述
- 没有关于运行时行为的信息
- 除非您粘贴错误，否则无法访问错误

**AI不是通灵者。AI是一个只能看到您向他们展示的内容的结对程序员。**

### 4. 对"重新开始"的困惑

**开发20小时后的用户：**
> "这坏了。我应该开始一个新项目吗？"

**现实检验：** 您不会在传统开发中丢弃20小时的工作。为什么在AI开发中会这样做？

**"重新开始"的真正含义：**
- ✅ 新聊天窗口（完全没问题，有助于上下文）
- ❌ 新项目（浪费时间，无法解决问题）

**问题不是项目。是您的调试过程。**

---

## 人类优先框架

### 核心原则

**在要求AI调试之前，先调试人类上下文。**

```
┌─────────────────────────────────────────────┐
│ 传统（错误）调试流程                        │
├─────────────────────────────────────────────┤
│ 1. 某事坏了                                │
│ 2. 告诉AI"它坏了"                          │
│ 3. AI猜测并更改代码                         │
│ 4. 仍然坏了                                │
│ 5. 重复20次                                │
│ 6. 放弃/重新开始                            │
└─────────────────────────────────────────────┘

┌─────────────────────────────────────┐
│ 人类优先（正确）调试流程                      │
├─────────────────────────────────────┤
│ 1. 某事坏了                                │
│ 2. 人类收集上下文：                          │
│    - 控制台错误                             │
│    - 网络请求                               │
│    - 复现步骤                               │
│    - 您期望的vs实际发生的事情                 │
│ 3. 给AI完整画面                            │
│ 4. AI立即识别根本原因                        │
│ 5. 首次尝试修复                            │
└─────────────────────────────────────┘
```

### 3步流程

#### 步骤1：收集上下文（人类执行）

**在接触AI之前，收集：**

1. **控制台输出**
   - 打开浏览器DevTools（F12）
   - 检查控制台选项卡
   - 复制所有错误消息
   - 包括堆栈跟踪

2. **网络活动**
   - 在DevTools中检查网络选项卡
   - 查找失败的请求（红色）
   - 检查请求/响应数据
   - 注意状态码（404、500等）

3. **复现步骤**
   - 写下复现的确切步骤
   - 包括您点击、键入、选择的内容
   - 注意错误何时出现

4. **期望vs实际**
   - 您期望发生什么
   - 实际发生了什么
   - 它们之间的差异

5. **环境详情**
   - 浏览器/设备
   - 操作系统
   - 相关设置

#### 步骤2：向AI提供完整上下文

**好的AI调试请求：**

```
"用户尝试提交联系表单时出现错误。

上下文：
1. 控制台错误：
   ```
   TypeError: Cannot read property 'value' of null
   at submitForm (contact.js:45)
   ```

2. 网络请求：
   - POST /api/contact 返回 400错误请求
   - 响应：{"error": "Missing required field: email"}

3. 复现步骤：
   - 填写姓名字段
   - 跳过电子邮件字段
   - 点击提交按钮
   - 错误出现

4. 期望：表单验证应在提交前显示错误
5. 实际：表单提交，服务器拒绝，页面显示通用错误

代码位置：contact.js第40-50行

您能帮助识别为什么客户端验证不起作用吗？"
```

**坏的AI调试请求：**

```
"表单坏了修复它"
```

#### 步骤3：引导AI完成过程

**如果调试很复杂：**
- 逐步给AI上下文
- 使用Chrome DevTools MCP等工具让AI看到实时数据
- 引导AI检查特定内容
- 对每个尝试的修复提供反馈

**使用工具的示例：**
```
"让我与您分享浏览器控制台输出。
[使用DevTools MCP捕获控制台]

现在让我们检查网络请求。
[使用DevTools MCP捕获网络]

基于此数据，根本原因是什么？"
```

---

## 真实世界示例

### 示例1："登录不起作用"

#### ❌ 坏方法（代码优先）

```
开发人员："登录不起作用。这是我的认证代码。"
[粘贴200行认证代码]

AI："我看到密码哈希可能存在一个问题。试试这个修复。"
[提供代码更改]

开发人员："仍然不起作用。"

AI："让我们检查会话管理..."
[提供另一个修复]

开发人员："仍然不起作用。这个AI没用。"
```

**结果：** 浪费30分钟，仍然坏了。

**为什么失败：** 没有上下文。AI在盲目猜测。

#### ✅ 好方法（人类优先）

```
开发人员："用户无法登录。让我先收集上下文。"

[打开DevTools，尝试登录]

开发人员："找到了。这是上下文：

控制台错误：
POST /api/login 401未授权
响应：{"error": "Invalid credentials"}

我做了什么：
1. 输入邮箱：test@example.com
2. 输入密码：（正确密码）
3. 点击登录

网络选项卡：
请求载荷：{"email": "test@example.com", "password": "password123"}

期望：成功登录
实际：401错误

有趣：请求中的密码字面意思是'password123'
而不是我输入的密码。在读取密码字段值时
某些地方出错了。"

AI："我看到问题了。login.js第23行正在从错误的
表单字段读取。您正在获取占位符文本而不是实际
输入值。将getElementById('password').placeholder改为
getElementById('password').value"

开发人员："完美！那修复了它。"
```

**结果：** 收集上下文2分钟，修复30秒。

**为什么有效：** 完整上下文允许AI立即识别确切问题。

### 示例2："页面很慢"

#### ❌ 坏方法

```
开发人员："页面真的很慢。优化它。"

AI："让我们实现延迟加载、代码拆分和记忆化。"
[提供复杂的优化代码]

开发人员："仍然很慢。试试别的。"

AI："让我们添加服务工作者和缓存..."
```

**结果：** 2小时的过早优化，仍然很慢。

#### ✅ 好方法

```
开发人员："页面感觉很慢。让我先调查。"

[打开DevTools性能选项卡，记录加载]
[检查网络选项卡]

开发人员："找到问题：

上下文：
- 初始页面加载：8秒
- 网络选项卡显示：下载英雄图像（12MB！）
- 没有其他请求很慢
- 图像加载后，一切都很快

用户环境：
- 移动设备
- 3G连接
- 图像以完整的600x4000分辨率加载

期望：页面在<2秒内加载
实际：等待巨大图像8秒

问题不是代码性能。是移动设备上的12MB图像。

解决方案：调整图像大小，添加响应式srcset，为网络压缩？"

AI："完全正确。以下是实现响应式图像的方法..."
```

**结果：** 5分钟识别真实问题，10分钟实现正确修复。

**为什么有效：** 调查揭示了实际瓶颈，避免了错误优化的时间浪费。

### 示例3："功能坏了"

#### ❌ 坏方法

```
开发人员："购物车不起作用。调试它。"

AI："我将检查状态管理问题..."
[对Redux存储进行更改]

开发人员："不，是别的东西。"

AI："也许是API端点..."
[进行后端更改]

开发人员："用户仍然抱怨。"
```

**结果：** 盲目追逐，多个错误修复。

#### ✅ 好方法

```
开发人员："用户报告购物车问题。让我重现这个。"

[尝试使用购物车功能]
[在使用功能时录制屏幕]

开发人员："这是我发现的：

用户报告："购物车不起作用"

复现：
1. 用户将商品添加到购物车 → ✅ 工作
2. 商品出现在购物车中 → ✅ 工作
3. 用户点击结账 → ✅ 工作
4. 付款页面加载 → ✅ 工作
5. 用户输入付款信息 → ✅ 工作
6. 用户点击支付 → ❌ 没有反应

控制台错误：
Uncaught Error: Payment processor ID is undefined
at processPayment (checkout.js:89)

网络：
POST /api/payment - 从未触发

根本原因：支付按钮应该提交付款
但找不到环境变量中的处理器ID。

环境检查：
开发：PAYMENT_PROCESSOR_ID=pk_test_xxx ✅
生产：PAYMENT_PROCESSOR_ID=(未设置) ❌

代码很好。这是部署配置问题。
需要在生产环境中设置PAYMENT_PROCESSOR_ID。"

AI："正确的诊断。以下是安全添加该环境
变量到您的生产部署而不暴露机密的方法..."
```

**结果：** 问题识别为部署配置，而不是代码错误。节省了调试错误问题的数小时。

**为什么有效：** 系统调查揭示了真实问题，是基础设施，而不是代码。

---

## 上下文收集检查清单

### 每次出现问题时：

#### 🔍 调查步骤

**1. 控制台错误**
- [ ] 打开DevTools（F12或Cmd+Option+I）
- [ ] 检查控制台选项卡的红色错误
- [ ] 复制完整错误消息
- [ ] 复制堆栈跟踪
- [ ] 注意行号

**2. 网络活动**
- [ ] 在DevTools中检查网络选项卡
- [ ] 识别失败的请求（红色状态）
- [ ] 检查请求方法（GET、POST等）
- [ ] 检查状态码（404、500、401等）
- [ ] 检查请求载荷
- [ ] 检查响应数据
- [ ] 检查响应头

**3. 应用状态**
- [ ] 检查Application/Storage选项卡
- [ ] 验证localStorage/sessionStorage
- [ ] 检查cookie
- [ ] 验证认证令牌
- [ ] 检查服务工作者（如适用）

**4. 复现步骤**
- [ ] 写下复现的确切步骤
- [ ] 注意您点击/键入的内容
- [ ] 记录时间（立即vs延迟）
- [ ] 测试是否一致或间歇性
- [ ] 尝试在不同浏览器/设备中

**5. 期望vs实际**
- [ ] 应该发生什么（期望行为）
- [ ] 实际发生什么（观察行为）
- [ ] 它们之间的差异
- [ ] 为什么您期望该行为

**6. 代码上下文**
- [ ] 识别涉及的文件/函数
- [ ] 检查该代码的最近更改
- [ ] 注意相关文件或依赖项
- [ ] 考虑可能的变化

**7. 环境详情**
- [ ] 浏览器和版本
- [ ] 操作系统
- [ ] 设备类型（桌面/移动/平板）
- [ ] 屏幕尺寸（如果是UI相关）
- [ ] 网络连接质量
- [ ] 任何相关设置或配置

### 在询问AI之前：

**最低要求上下文：**
- ✅ 控制台错误消息（如果有）
- ✅ 您试图做什么
- ✅ 实际发生了什么
- ✅ 复现步骤

**理想的完整上下文：**
- ✅ 以上全部加上：
- ✅ 网络请求/响应详情
- ✅ 相关代码位置
- ✅ 您已经尝试的内容
- ✅ 环境详情

---

## 何时涉及AI

### ✅ 当您拥有以下内容时涉及AI：

1. **完整错误上下文**
   ```
   "得到此错误：[粘贴错误]
   当执行：[步骤]
   期望：[结果]
   网络显示：[请求详情]
   代码位置：[文件:行]"
   ```

2. **具体技术问题**
   ```
   "此函数返回undefined，而我期望数组。
   这是函数：[代码]
   这是我如何调用它的：[代码]
   控制台显示：[输出]
   我的方法有什么问题？"
   ```

3. **调查后的架构决策**
   ```
   "我确定瓶颈在数据库查询中。
   当前：每页加载50个查询
   每个查询需要：100ms
   总计：5秒加载时间

   考虑：
   1. 实现缓存
   2. 使用查询批处理
   3. 添加数据库索引

   哪种方法最适合此用例？"
   ```

### ❌ 当您没有以下内容时不要涉及AI：

1. **检查错误**
   ```
   ❌ "它不起作用，修复它"
   ✅ "让我先检查控制台... [找到错误] ...现在我可以问AI了"
   ```

2. **尝试基本调查**
   ```
   ❌ "页面很慢，优化它"
   ✅ "让我先分析它... [找到问题] ...现在我可以问AI了"
   ```

3. **理解发生了什么**
   ```
   ❌ "功能坏了，不知道为什么"
   ✅ "让我重现它... [重现] ... [检查日志] ...现在我理解什么坏了"
   ```

### 使用工具引导AI

**AI没有眼睛。您有。您是AI的眼睛。**

#### 手动上下文收集（始终可用）

```
1. 您打开DevTools
2. 您复制错误消息
3. 您粘贴到AI聊天中
4. AI分析并建议修复
```

#### 工具辅助上下文收集（可选）

一些AI工具提供MCP（模型上下文协议）集成，如Chrome DevTools MCP：

```
1. 您将DevTools MCP连接到您的AI工具
2. AI可以请求特定信息：
   - "显示控制台错误"
   - "什么网络请求失败了？"
   - "截取当前状态的屏幕截图"
3. 工具直接向AI提供数据
4. AI分析并建议修复
```

**两种方法都有效。关键是：首先收集上下文。**

**工具辅助更快，但手动始终有效。**

### 引导AI完成复杂调试

**对于复杂问题，成为调查员：**

```
开发人员："支付流程有时失败。让我调查。"

[多次测试支付流程]
[注意到模式]

开发人员："我找到了一个模式：
- 80%的时间工作
- 用户在页面加载后快速点击支付按钮时失败
- 控制台错误仅在快速点击时出现
- 错误：'paymentProcessor未初始化'

让我检查初始化代码..."

[检查代码]

开发人员："找到了：
- 支付处理器异步初始化
- 支付按钮立即启用
- 如果用户在初始化完成前点击，它失败了

AI：按钮应在处理器准备就绪前禁用。
这是修复：[解决方案]"
```

**您引导调查。AI根据您的发现提供解决方案。**

---

## "重新开始"的神话

### 20小时项目场景

**情况：**
> "我已经在这个项目上工作了20小时。现在有一个我无法修复的错误。我应该重新开始吗？"

**绝对不是。**

**为什么会发生：**

1. **挫折影响判断**
   - 调试数小时没有进展后
   - 感觉一切都坏了
   - 认为从头开始会更容易

2. **缺少：不是项目，是过程问题**
   - 您的代码不是问题
   - 您的调试方法是
   - 重新开始将导致相同问题

3. **混淆：新聊天vs新项目**
   - ✅ **新聊天窗口**：好主意！新上下文，清晰对话
   - ❌ **新项目**：浪费20小时，不解决任何问题

### 何时"重新开始"有意义

#### ✅ 开始新聊天窗口当：

- 对话变得太长和混乱
- 需要重组您的想法
- 想尝试相同问题的不同方法
- 当前聊天充满死胡同和混乱

**您保留项目。只是新对话。**

#### ✅ 开始新项目当：

- 您构建了原型来测试概念（现在真正构建）
- 架构对需求根本错误
- 对用例使用了错误的技术栈
- 学习项目→现在构建生产版本

**罕见情况。通常不是答案。**

#### ❌ 不要重新开始当：

- 您还没有收集适当的上下文
- 您还没有检查基本错误
- 您很沮丧但不知道哪里错了
- AI不"理解它"（问题：您的上下文，不是AI）
- 项目很复杂（投入了20+小时）

### 真正的修复：调试您的过程

**而不是重新开始：**

```
1. 停止编码30分钟
2. 退后并正确调查
3. 打开DevTools
4. 系统地重现问题
5. 收集完整上下文
6. 记录您的发现
7. 然后用完整上下文问AI
```

**如果您在项目上花费了20小时：**
- 您有工作的代码
- 您有架构
- 您有逻辑
- 您有UI
- 重新开始会丢弃所有这些

**更好的方法：**
```
"我在这个20小时的项目上遇到了障碍。在我做任何激进的事情之前，
让我正确调查这个错误。

[花30分钟收集上下文]
[找到实际问题]

哦。是环境变量中的拼写错误。
[在2分钟内修复]

想象一下如果我重新开始了..."
```

### 重新开始很容易，调试是专业的

**初级心态：**
> "这很难。让我重新开始并以不同的方式做它。"

**专业心态：**
> "这很难。让我系统地调查，理解根本原因，并正确修复它。"

**重新开始是避免问题，而不是解决问题。**

---

## 常见场景

### 场景1："本地工作但在生产中不工作"

#### ❌ 坏方法
```
开发人员："在本地工作但在生产中不工作。重新部署它。"

AI："尝试重建和重新部署..."

开发人员："在生产中仍然不工作。"
```

#### ✅ 好方法
```
开发人员："在本地工作，生产中失败。让我检查差异：

本地环境：
- Node版本：18.x
- 环境变量：[列出变量]
- 数据库：localhost
- API端点：http://localhost:3000

生产环境：
- Node版本：16.x（不同！）
- 环境变量：[检查部署配置]
  → 缺少：DATABASE_URL ❌
  → 缺少：API_KEY ❌
- 数据库：[生产URL]
- API端点：https://api.production.com

生产日志：
Error: Cannot find module 'some-package'
→ 包使用Node 18功能
→ 生产是Node 16

发现问题：
1. Node版本不匹配
2. 缺少环境变量
3. 依赖不兼容

现在我可以问AI：'我如何配置生产环境以匹配
本地要求并处理版本差异？'"
```

### 场景2："测试失败"

#### ❌ 坏方法
```
开发人员："我的更改后测试失败。修复测试。"

AI："这是更新的测试代码..."

开发人员："仍然10个测试失败。"
```

#### ✅ 好方法
```
开发人员："测试失败。让我看看哪些以及为什么：

测试结果：
✅ 45通过
❌ 10失败

失败测试（常见模式）：
- 都在auth.test.js中
- 都期望特定API响应格式
- 都失败：期望对象，得到undefined

我的更改：
- 修改了API响应结构
- 从{ data: { user } }改为{ user }
- 测试期望旧结构

根本原因：测试对旧API结构是正确的。
我的代码更改了API结构。

选项：
1. 更新测试以匹配新结构（如果新结构更好）
2. 恢复到旧结构（如果测试代表合同）
3. 支持两者以向后兼容

AI：哪种方法最适合此API用例？"
```

### 场景3："随机间歇错误"

#### ❌ 坏方法
```
开发人员："有时得到随机错误。没有模式。修复它。"

AI："尝试添加错误处理..."

开发人员："仍然随机发生。"
```

#### ✅ 好方法
```
开发人员："得到间歇错误。让我收集数据：

观察：
- 错误出现在约30%的请求中
- 初看没有明显模式
- 相同代码，不同结果

调查：
[监控10个请求]
[注意哪些失败]

发现模式：
- 服务器响应超过5秒时失败
- 并行多个请求时失败
- 特别是：/api/data端点

错误消息（发生时）：
"TypeError: Cannot read property 'items' of undefined"

代码分析：
- 端点返回数据结构：{ items: [] }
- 但有时返回：{ error: "Timeout" }
- 代码假设items总是存在 ❌

根本原因：没有超时响应的错误处理。
代码期望items数组但得到错误对象。

AI上下文：
'此端点根据成功/超时返回不同结构。
如何优雅地处理两种情况？'"
```

### 场景4："AI不断给出错误解决方案"

#### ❌ 坏方法
```
开发人员："AI给了我5次错误解决方案。这个AI很烂。"
[切换到不同的AI]
开发人员："新AI也给出错误解决方案。"
```

#### ✅ 好方法
```
开发人员："AI没有解决这个问题。让我检查我的上下文：

我一直说的：
'修复按钮点击处理器'

我没有提供的：
- 按钮应该做什么
- 发生什么错误
- 发生vs应该发生什么
- 任何控制台错误
- 实际代码

哦。我要求AI修复某些东西而不解释问题。

带有上下文的新方法：
'提交按钮应该将表单数据发送到/api/submit。

期望：点击→验证→POST请求→成功消息
实际：点击→什么都没发生

控制台错误：
ReferenceError: submitForm未定义
at HTMLButtonElement.onclick (index.html:42)

代码：
HTML: <button onclick="submitForm()">提交</button>
JS: 未定义submitForm函数 ❌

啊！函数在JS中称为handleSubmit但在HTML中引用为
submitForm。
AI：这是命名不匹配。将X改为Y？'

AI：'是的，完全正确。将onclick="submitForm()"改为
onclick="handleSubmit()"或重命名函数。'

开发人员：'那是我的错，没有提供上下文。'"
```

---

## 最佳实践

### ✅ DO：

1. **询问前调查**
   - 首先打开DevTools
   - 首先检查控制台
   - 首先查看网络请求
   - 然后用数据问AI

2. **提供完整上下文**
   - 错误消息（确切文本）
   - 复现步骤（确切点击）
   - 期望vs实际（具体说明）
   - 代码位置（文件:行）
   - 环境详情（浏览器/操作系统/设备）

3. **引导调查**
   - 您是AI的眼睛和耳朵
   - 您可以看到运行时状态
   - 您可以打开DevTools
   - 您重现问题
   - 您收集事实
   - AI分析事实并提供解决方案

4. **在有帮助时使用工具**
   - DevTools MCP用于自动化上下文收集
   - 但手动上下文收集始终有效
   - 根据什么对您更快选择

5. **记录您的发现**
   - 写下您发现的内容
   - 在分享前组织上下文
   - 让AI更容易帮助
   - 让您更容易清晰思考

6. **系统地测试假设**
   - 一次更改一件事
   - 验证每个更改
   - 将结果报告给AI
   - 基于数据迭代

7. **需要时新聊天**
   - 长而混乱的对话→新聊天
   - 保留项目，新上下文
   - 总结旧聊天中的发现
   - 用干净的白板继续

### ❌ DON'T：

1. **不要跳过调查**
   - ❌ "它坏了，修复它"
   - ✅ "让我先检查什么坏了"

2. **不要期望AI是通灵者**
   - ❌ "登录有些问题"
   - ✅ "登录返回401，控制台显示：[错误]，网络显示：[数据]"

3. **不要过早重新开始**
   - ❌ "错误很难，让我开始新项目"
   - ✅ "错误很难，让我正确调查"

4. **不要提供模糊上下文**
   - ❌ "页面很慢"
   - ✅ "页面加载需要8秒，DevTools显示12MB图像加载"

5. **不要猜测解决方案**
   - ❌ "也许是数据库？还是缓存？还是...？"
   - ✅ "让我收集数据以识别实际瓶颈"

6. **不要责怪工具**
   - ❌ "这个AI模型不擅长调试"
   - ✅ "我需要为AI提供更好的上下文"

7. **不要匆忙**
   - ❌ "快速，尝试随机修复直到某些东西工作"
   - ✅ "花10分钟正确调查，节省数小时猜测"

---

## 总结：人类优先调试心态

```
┌─────────────────────────────────────────────────────┐
│                                                             │
│  95%的"AI无法调试这个"实际上是                              │
│  "人类没有提供上下文"                                         │
│                                                             │
│  在要求AI调试之前：                                          │
│  1. 打开DevTools                                            │
│  2. 检查控制台错误                                           │
│  3. 检查网络请求                                            │
│  4. 重现问题                                                │
│  5. 收集完整上下文                                           │
│                                                             │
│  然后向AI提供：                                              │
│  - 确切错误消息                                             │
│  - 复现步骤                                                 │
│  - 期望vs实际行为                                           │
│  - 网络请求/响应数据                                        │
│  - 代码位置                                                 │
│  - 环境详情                                                 │
│                                                             │
│  AI是您的结对程序员，不是通灵者。                            │
│  您是AI的眼睛。收集上下文。然后协作。                        │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 记住：

- **您不会在传统开发中重启20小时的项目**
- **在AI辅助开发中也不要重启它**
- **修复过程（上下文收集），而不是项目**
- **新聊天≠新项目**
- **自动化前的调查**
- **人类上下文第一，AI解决方案第二**

---

## 相关资源

- [故障排除指南](README.md) - 完整故障排除参考
- [调试提示](../prompting/task-specific-patterns.md#debugging--error-resolution) - 有效调试通信的模板
- [第3阶段：测试和调试](../workflow/phase-3-testing-debugging.md) - 工作流程集成
- [DevTools MCP设置](../workflow/phase-2-development.md#prerequisites-environment-setup) - 可选工具辅助上下文收集

---

**不舒服的真相？**

大多数调试问题是人类上下文问题。

**好消息？**

现在您知道如何修复它们了。🎯